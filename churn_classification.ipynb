{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15634602</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15647311</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15619304</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15701354</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15737888</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "CustomerId                                                                  \n",
       "15634602            619   42       2       0.00              1          1   \n",
       "15647311            608   41       1   83807.86              1          0   \n",
       "15619304            502   42       8  159660.80              3          1   \n",
       "15701354            699   39       1       0.00              2          0   \n",
       "15737888            850   43       2  125510.82              1          1   \n",
       "\n",
       "            IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "CustomerId                                                              \n",
       "15634602                 1        101348.88       1                 1   \n",
       "15647311                 1        112542.58       0                 0   \n",
       "15619304                 0        113931.57       1                 1   \n",
       "15701354                 0         93826.63       0                 1   \n",
       "15737888                 1         79084.10       0                 0   \n",
       "\n",
       "            Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "CustomerId                                                                  \n",
       "15634602                    0                0              1            0  \n",
       "15647311                    0                1              1            0  \n",
       "15619304                    0                0              1            0  \n",
       "15701354                    0                0              1            0  \n",
       "15737888                    0                1              1            0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/Task_2/account_histroy_data.csv\", index_col=1).drop(\"RowNumber\", axis=1)\n",
    "test = pd.read_csv(\"data/Task_2/existing_account.csv\", index_col=0)\n",
    "\n",
    "# drop unused columns\n",
    "drop_cols = [\"Surname\"]\n",
    "train.drop(drop_cols, axis=1, inplace=True)\n",
    "test.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "# binarize categorical columns\n",
    "cat_cols = [\"Geography\", \"Gender\"]\n",
    "for column in cat_cols:\n",
    "    train = pd.merge(\n",
    "        train.drop(column, axis=1),\n",
    "        pd.get_dummies(train[column]).add_prefix(column + \"_\"),\n",
    "        left_index=True, right_index=True\n",
    "    )\n",
    "    test = pd.merge(\n",
    "        test.drop(column, axis=1),\n",
    "        pd.get_dummies(test[column]).add_prefix(column + \"_\"),\n",
    "        left_index=True, right_index=True\n",
    "    )\n",
    "    \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss, accuracy_score, recall_score, cohen_kappa_score\n",
    "\n",
    "metric_funcs = {\n",
    "    \"log_loss\": log_loss,\n",
    "    \"recall_score\": recall_score,\n",
    "    \"accuracy_score\": accuracy_score,\n",
    "    \"cohen_kappa_score\": cohen_kappa_score\n",
    "}\n",
    "\n",
    "\n",
    "def cross_validate(Model, params, data, t_col = \"Exited\"):\n",
    "    log = []\n",
    "    for i, (tr_i, t_i) in enumerate(KFold(n_splits=5).split(data)):\n",
    "        X_tr, y_tr = data.drop(t_col, axis=1).iloc[tr_i], data[t_col].iloc[tr_i]\n",
    "        X_t, y_t = data.drop(t_col, axis=1).iloc[t_i], data[t_col].iloc[t_i]\n",
    "        model = Model(**params)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        pred = model.predict(X_t)\n",
    "        log.append({\n",
    "            **{n: f(y_t, pred) for n, f in metric_funcs.items()},\n",
    "            **params\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(log).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "N = 5\n",
    "CORES = cpu_count()\n",
    "\n",
    "# sample from generated parameter space for cv\n",
    "def sample(space):\n",
    "    params = {}\n",
    "    for k in space.keys():\n",
    "        params[k] = random.choice(space[k])\n",
    "\n",
    "    return params\n",
    "\n",
    "# iterate over param spaces and aggregate results\n",
    "def cv_for_params(Model, param_space, param_statics):\n",
    "    return pd.concat([\n",
    "        cross_validate(\n",
    "            Model,\n",
    "            {**sample(param_space), **param_statics},\n",
    "            train\n",
    "        ) for i in range(N)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_space = {\n",
    "    'learning_rate': np.geomspace(1e-2, 1),\n",
    "    'max_depth': list(range(1, 10)),\n",
    "    'gamma': np.geomspace(1e-2, 1),\n",
    "    'min_child_weight': list(range(1, 10)),\n",
    "    'num_estimators': list(range(30, 300)),\n",
    "    'reg_alpha': np.linspace(0.2, 1),\n",
    "    'reg_lambda': np.linspace(0.2, 2),\n",
    "    'scale_pos_weight': np.linspace(0.3, 2)\n",
    "}\n",
    "param_statics = {'n_jobs': CORES}\n",
    "\n",
    "xgb_results = cv_for_params(\n",
    "    XGBClassifier,\n",
    "    param_space,\n",
    "    param_statics,\n",
    ")\n",
    "xgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>cohen_kappa_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>cohen_kappa_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>cohen_kappa_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>cohen_kappa_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>cohen_kappa_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.664433</td>\n",
       "      <td>-0.008826</td>\n",
       "      <td>10.308333</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.766495</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>7.374471</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.778866</td>\n",
       "      <td>-0.003354</td>\n",
       "      <td>6.925565</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.781443</td>\n",
       "      <td>-0.005116</td>\n",
       "      <td>6.836542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754124</td>\n",
       "      <td>-0.006582</td>\n",
       "      <td>7.619917</td>\n",
       "      <td>0.039062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.701546</td>\n",
       "      <td>0.050415</td>\n",
       "      <td>11.590203</td>\n",
       "      <td>0.223058</td>\n",
       "      <td>0.786488</td>\n",
       "      <td>0.049420</td>\n",
       "      <td>8.065008</td>\n",
       "      <td>0.077694</td>\n",
       "      <td>0.799485</td>\n",
       "      <td>0.022355</td>\n",
       "      <td>7.637705</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.802062</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>7.548682</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>0.779381</td>\n",
       "      <td>0.030147</td>\n",
       "      <td>8.492300</td>\n",
       "      <td>0.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.682854</td>\n",
       "      <td>0.014124</td>\n",
       "      <td>10.953974</td>\n",
       "      <td>0.208869</td>\n",
       "      <td>0.776576</td>\n",
       "      <td>0.034486</td>\n",
       "      <td>7.716820</td>\n",
       "      <td>0.065304</td>\n",
       "      <td>0.790495</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>7.236066</td>\n",
       "      <td>0.018148</td>\n",
       "      <td>0.795031</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>7.079377</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.771214</td>\n",
       "      <td>0.011948</td>\n",
       "      <td>7.902012</td>\n",
       "      <td>0.052714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy_score  cohen_kappa_score   log_loss  recall_score  \\\n",
       "min         0.664433          -0.008826  10.308333      0.200521   \n",
       "max         0.701546           0.050415  11.590203      0.223058   \n",
       "mean        0.682854           0.014124  10.953974      0.208869   \n",
       "\n",
       "      accuracy_score  cohen_kappa_score  log_loss  recall_score  \\\n",
       "min         0.766495           0.013659  7.374471      0.052083   \n",
       "max         0.786488           0.049420  8.065008      0.077694   \n",
       "mean        0.776576           0.034486  7.716820      0.065304   \n",
       "\n",
       "      accuracy_score  cohen_kappa_score  log_loss  recall_score  \\\n",
       "min         0.778866          -0.003354  6.925565      0.007557   \n",
       "max         0.799485           0.022355  7.637705      0.023438   \n",
       "mean        0.790495           0.010933  7.236066      0.018148   \n",
       "\n",
       "      accuracy_score  cohen_kappa_score  log_loss  recall_score  \\\n",
       "min         0.781443          -0.005116  6.836542      0.000000   \n",
       "max         0.802062           0.007990  7.548682      0.005038   \n",
       "mean        0.795031           0.001910  7.079377      0.002502   \n",
       "\n",
       "      accuracy_score  cohen_kappa_score  log_loss  recall_score  \n",
       "min         0.754124          -0.006582  7.619917      0.039062  \n",
       "max         0.779381           0.030147  8.492300      0.063830  \n",
       "mean        0.771214           0.011948  7.902012      0.052714  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_space = {\n",
    "    'n_neighbors': list(range(1, 25)),\n",
    "}\n",
    "param_statics = {'n_jobs': CORES}\n",
    "\n",
    "knn_results = pd.concat([\n",
    "    cross_validate(\n",
    "        KNeighborsClassifier,\n",
    "        {**sample(param_space), **param_statics},\n",
    "        train\n",
    "    ) for i in range(N)\n",
    "])\n",
    "knn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/westi/Repos/infotest/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/Users/westi/Repos/infotest/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-5b0924eba451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparam_statics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     ) for i in range(N)\n\u001b[0m\u001b[1;32m     22\u001b[0m ], axis=1)\n\u001b[1;32m     23\u001b[0m \u001b[0mffn_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-5b0924eba451>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparam_statics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     ) for i in range(N)\n\u001b[0m\u001b[1;32m     22\u001b[0m ], axis=1)\n\u001b[1;32m     23\u001b[0m \u001b[0mffn_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-fd6f1d7476b6>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(Model, params, data, t_col)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mX_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_funcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/infotest/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \"\"\"\n\u001b[1;32m    976\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 977\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/infotest/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                            incremental):\n\u001b[1;32m    341\u001b[0m             \u001b[0;31m# First time training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# lbfgs does not support mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/infotest/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, y, layer_units)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             coef_init, intercept_init = self._init_coef(layer_units[i],\n\u001b[0;32m--> 283\u001b[0;31m                                                         layer_units[i + 1])\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/infotest/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_init_coef\u001b[0;34m(self, fan_in, fan_out)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# Generate weights and bias:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         coef_init = self._random_state.uniform(-init_bound, init_bound,\n\u001b[0;32m--> 306\u001b[0;31m                                                (fan_in, fan_out))\n\u001b[0m\u001b[1;32m    307\u001b[0m         intercept_init = self._random_state.uniform(-init_bound, init_bound,\n\u001b[1;32m    308\u001b[0m                                                     fan_out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "param_space = {\n",
    "    'hidden_layer_sizes': tuple([\n",
    "        [\n",
    "            random.choice(list(range(2, train.shape[1])))\n",
    "            for i in range(random.choice(list(range(1,4))))]\n",
    "    ]),\n",
    "    'activation': ['relu', 'tanh', 'logistic']\n",
    "}\n",
    "param_statics = {'early_stopping': True}\n",
    "\n",
    "ffn_results = pd.concat([\n",
    "    cross_validate(\n",
    "        MLPClassifier,\n",
    "        {**sample(param_space), **param_statics},\n",
    "        train\n",
    "    ) for i in range(N)\n",
    "], axis=1)\n",
    "ffn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
